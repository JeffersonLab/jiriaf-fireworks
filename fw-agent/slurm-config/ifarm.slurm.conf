# /etc/slurm/slurm.conf
# See the slurm.conf man page for more information.
#
ControlMachine=enpslurm21
AuthType=auth/munge
AuthAltTypes=auth/jwt  # (at least initially) for ychen exploring slurmrestd
#CheckpointType=checkpoint/none
CryptoType=crypto/munge
DisableRootJobs=NO
#MemSpecLimit=100       # Protect slurm processes from OOM killer (need cgroup on too)
EnforcePartLimits=ALL   # Enforce Partition Limits. Reject jobs that can never run.
Epilog=/usr/local/libexec/slurm/epilog.d/*
#EpilogSlurmctld=
# Remove after enpslurm21 upgrade is compelted:
#FirstJobId=50000000
# The maximun allowed local job id is 67,108,863. After that it will wrap for FirstJobId
#MaxJobId=999999
GresTypes=disk,gpu
#GroupUpdateForce=0
#GroupUpdateTime=600
#JobCheckpointDir=/var/slurm/checkpoint
#JobCredentialPrivateKey=
#JobCredentialPublicCertificate=
#JobFileAppend=0
#JobRequeue=1
#JobSubmitPlugins=
#KillOnBadExit=0
#LaunchType=launch/slurm
#Licenses=foo*4,bar
MailProg=/bin/smail
MaxJobCount=500000
MaxArraySize=10001
#MaxStepCount=40000
#MaxTasksPerNode=128
MpiDefault=none
#MpiParams=ports=#-#
#PluginDir=
#PlugStackConfig=
#PrivateData=jobs
ProctrackType=proctrack/cgroup
Prolog=/usr/local/libexec/slurm/prolog.d/*
#PrologFlags=
#PrologSlurmctld=
#PropagatePrioProcess=0
#PropagateResourceLimits=
PropagateResourceLimitsExcept=MEMLOCK,NPROC
ReturnToService=1
#SallocDefaultCommand=
SlurmctldPidFile=/var/run/slurm/slurmctld.pid
# Attempt to address 2024-02-15 sockstat plateau and Listen{Drop,Overflow}s.
# We should be fine to include SlurmdPort in the range per the man-page
# since we do not run slurmd and slurmctld on the same host.
SlurmctldPort=6817-6818
SlurmdPidFile=/var/run/slurm/slurmd.pid
SlurmdPort=6818
SlurmdSpoolDir=/var/spool/slurm/d
SlurmUser=slurm
#SlurmdUser=root
#SrunEpilog=
#SrunProlog=
StateSaveLocation=/var/spool/slurm/ctld
SwitchType=switch/none
#TaskEpilog=
TaskPlugin=task/cgroup,task/affinity
#TaskPlugin=task/none
#TaskPluginParam=
TaskProlog=/usr/local/libexec/slurm/taskprolog.sh
TopologyPlugin=topology/none
TmpFS=/scratch
#TrackWCKey=no
#TreeWidth=
#UnkillableStepProgram=
#UsePAM=0
#
# TIMERS
#BatchStartTimeout=10
#CompleteWait=0
#EpilogMsgTime=2000
#GetEnvTimeout=2
InactiveLimit=0
KillWait=30
#MessageTimeout=10
#ResvOverRun=0
MinJobAge=3600  # keep completed job info for one hour
#OverTimeLimit=0
SlurmctldTimeout=120
SlurmdTimeout=300
UnkillableStepTimeout=120
#VSizeFactor=0
Waittime=0
#
# SCHEDULING
SchedulerType=sched/backfill
SchedulerParameters=bf_max_job_test=50000,default_queue_depth=10000,bf_job_part_count_reserve=1,bf_continue,max_rpc_cnt=500,sched_min_interval=2000000,bf_max_job_assoc=100,bf_window=5760,bf_resolution=240,defer,bf_interval=200,bf_busy_nodes,assoc_limit_continue,batch_sched_delay=10,partition_job_depth=0,bf_yield_interval=1000000,pack_serial_at_end,nohold_on_prolog_fail
SelectType=select/cons_tres
SelectTypeParameters=CR_CPU_Memory
PreemptType=preempt/partition_prio  # 2/7/2019 for preempt
PreemptMode=REQUEUE                 # 2/7/2019 for preempt
#
# JOB PRIORITY
#bhess 2019-07-09 switch to FAIR_TREE.
PriorityType=priority/multifactor
PriorityFlags=FAIR_TREE
#bhess - alow decay to take care of fairshare - 2019-07-05
PriorityUsageResetPeriod=NONE       # The default value is NONE
PriorityDecayHalfLife=7-0           # fairshare history contribution
#PriorityUsageResetPeriod=WEEKLY    # The default value is NONE
#PriorityWeightAge=1000             # The default value is 0
# bhess 2020-03-19 - change Age weight to zero. age is implicit in fairshare with decay over time
PriorityWeightAge=0
PriorityWeightFairshare=10000       # The default value is 0
#bhess 2020-03-19 - change job size weight to zero. job size is implicit in fairshare resource accounting over time
PriorityWeightJobSize=0
PriorityWeightPartition=10000       # The default value is 0
#
# JOB DEPENDENCY SETTINGS
# kill a job if its dependency can never be satisfied
DependencyParameters=kill_invalid_depend
#
# LOGGING AND ACCOUNTING
AccountingStorageEnforce=limits
AccountingStorageHost=enpslurm21
#AccountingStorageLoc=
#AccountingStoragePass=
AccountingStoragePort=6819
AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageUser=slurm
AccountingStoreFlags=job_comment,job_env,job_script
# Append GPU Accounting to TRES
AccountingStorageTRES=gres/gpu,gres/gpu:TitanRTX,gres/gpu:T4,gres/gpu:A100
ClusterName=scicomp
DebugFlags=NO_CONF_HASH
#JobCompHost=
JobCompLoc=/var/log/slurm/jobcomp
#JobCompPass=
#JobCompPort=
JobCompType=jobcomp/filetxt
#JobCompUser=
#JobContainerType=job_container/none
JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/cgroup
#SlurmctldDebug=3
SlurmctldLogFile=/var/log/slurm/slurmctld.log
#SlurmdDebug=3
SlurmdLogFile=/var/log/slurm/slurmd.log
SlurmSchedLogFile=/var/log/slurm/slurmSched.log
#SlurmSchedLogLevel=3
#
# REBOOT SETTINGS
# Custom script for handling lustre, etc. Use nhc to ensure mountpoints are
# up and available after reboot and set interval=0 to disable continuous
# checks. Allow up to ResumeTimeout for node to reboot.
RebootProgram=/usr/local/libexec/slurm/reboot.sh
HealthCheckProgram=/sbin/nhc-wrapper
HealthCheckInterval=0
ResumeTimeout=600
#
# POWER SAVE SUPPORT FOR IDLE NODES (optional)
#SuspendProgram=
#ResumeProgram=
#SuspendTimeout=
#ResumeRate=
#SuspendExcNodes=
#SuspendExcParts=
#SuspendRate=
#SuspendTime=
#
#
# COMPUTE NODES
#
# Notes:
#   CPUs - CPUs=Boards*Sockets*CoresPerSocket*ThreadsPerCore
#
#   CVMFS - disk sizing is dropped by 50G due to CVMFS cache.  It's defined in
#       /etc/cvmfs/default.local (puppet osg::worker)
#
#   Weights - Node weights are lower for machines with less memory/cpu to pack
#       them first. see the man page.  Nodes reserved for specific purposes
#       (JupyterHub, sciml) have lowest weights so they are used first if
#       there is overlap with other partitions.
#

# Alma 9.X
#NodeName=farm1601[01-04,07,09-33,35-36] \
#    Weight=160 \
#    Sockets=2 \
#    CoresPerSocket=18 \
#    ThreadsPerCore=2 \
#    CPUs=72 \
#    RealMemory=63142 \
#    Gres=disk:740G \
#    TmpDisk=740000 \
#    Feature=el9,farm16

# Alma 9.X
NodeName=farm180[101-104,106,108-136,201,203-216,221-228,234-236,241-245] \
    Weight=180 \
    Sockets=2 \
    CoresPerSocket=20 \
    ThreadsPerCore=2 \
    CPUs=80 \
    RealMemory=94157 \
    Gres=disk:265G \
    TmpDisk=265000 \
    Feature=el9,farm18

# Weighted for JupyterHub to prefer these nodes. Weight 100 is lower (better)
# than other farm nodes.
# Alma 9.X
NodeName=farm180[246-248,301] \
    Weight=100 \
    Sockets=2 \
    CoresPerSocket=20 \
    ThreadsPerCore=2 \
    CPUs=80 \
    RealMemory=94157 \
    Gres=disk:265G \
    TmpDisk=265000 \
    Feature=el9,farm18

# Alma 9.X
NodeName=farm19[01-17,19-35,37-59] \
    Weight=190 \
    Sockets=2 \
    CoresPerSocket=32 \
    ThreadsPerCore=2 \
    CPUs=128 \
    RealMemory=256617 \
    Gres=disk:750G \
    TmpDisk=750000 \
    Feature=el9,farm19

# Alma 9.X with ConnectX-4
NodeName=farm19[60-75,77-86,96-102,104-107] \
    Weight=192 \
    Sockets=2 \
    CoresPerSocket=32 \
    ThreadsPerCore=2 \
    CPUs=128 \
    RealMemory=256617 \
    Gres=disk:750G \
    TmpDisk=750000 \
    Feature=el9,farm19,cx4ib

# CentOS Linux 7.x with ConnectX-4
# !!! Currently reserved for covrig's fluent work !!!
# !!! Move to el9 group above once upgraded       !!!
NodeName=farm19[87-95] \
    Weight=192 \
    Sockets=2 \
    CoresPerSocket=32 \
    ThreadsPerCore=2 \
    CPUs=128 \
    RealMemory=256617 \
    Gres=disk:750G \
    TmpDisk=750000 \
    Feature=farm19,cx4ib

# farm1976 had 512GB, unlike the others. Weight it slightly higher (195>190
# for other farm19 nodes).
NodeName=farm1976 \
   Weight=195 \
   Sockets=2 \
   CoresPerSocket=32 \
   ThreadsPerCore=2 \
   CPUs=128 \
   RealMemory=514700 \
   Gres=disk:750G \
   TmpDisk=750000 \
   Feature=el9,farm19,cx4ib

# Alma 9.X
NodeName=farm23[01-25] \
    Weight=200 \
    CPUs=256 \
    Sockets=2 \
    CoresPerSocket=64 \
    ThreadsPerCore=2 \
    RealMemory=514695 \
    Gres=disk:7T \
    TmpDisk=7000000 \
    Feature=el9,farm23

NodeName=sciml190[2-3] \
  Weight=300 \
  Sockets=2 \
  CoresPerSocket=16 \
  ThreadsPerCore=2 \
  CPUs=64 \
  RealMemory=190899 \
  Gres=disk:750G,gpu:TitanRTX:4 \
  TmpDisk=750000 \
  Feature=el9,sciml19

NodeName=sciml2101 \
  Weight=300 \
  Sockets=2 \
  CoresPerSocket=32 \
  ThreadsPerCore=1 \
  CPUs=64 \
  RealMemory=514678 \
  Gres=disk:750G,gpu:T4:8 \
  TmpDisk=750000 \
  Feature=el9,sciml21

NodeName=sciml210[2-3] \
  Weight=300 \
  SocketsPerBoard=2 \
  CoresPerSocket=32 \
  ThreadsPerCore=1 \
  CPUs=64 \
  RealMemory=514678 \
  Gres=disk:750G,gpu:T4:16 \
  TmpDisk=750000 \
  Feature=el9,sciml21

NodeName=sciml230[1-2] \
  Weight=300 \
  SocketsPerBoard=8 \
  CoresPerSocket=4 \
  ThreadsPerCore=1 \
  CPUs=32 \
  RealMemory=514679 \
  Gres=disk:750G,gpu:A100:4 \
  TmpDisk=750000 \
  Feature=el9,sciml23

# Alma 9.X
NodeName=sciml240[1-2] \
  Weight=300 \
  CPUs=32 \
  Boards=1 \
  SocketsPerBoard=1 \
  CoresPerSocket=32 \
  ThreadsPerCore=1 \
  RealMemory=515072 \
  Gres=disk:1500G,gpu:A800:4 \
  TmpDisk=1500000 \
  Feature=el9,sciml24

#
# NodeSets
#
# Note: NodeSets can't be nested.
#
# Only a few nodes not in production_nodes.  GPU and dedicated nodes are
# expected in other NodeSets.
NodeSet=production_nodes  Nodes=\
farm180[101-104,106,108-136,201,203-216,221-228,234-236,241-245],\
farm19[01-17,19-35,37-102,104-107],\
farm23[01-25]

# Jupyter has a few nodes to itself for prompt interactive jobs.  Noted
# seperately for readability.
NodeSet=jupyter_only_nodes Nodes=\
farm180[246-248,301]
NodeSet=jupyter_shared_nodes Nodes=\
farm180[101-104,106,108-136,201,203-216,221-228,234-236,241-245],\
farm19[01-17,19-35,37-102,104-107],\
farm23[01-25]

# No farm19 access currently
NodeSet=theory_shared_nodes Nodes=\
farm180[101-104,106,108-136,201,203-216,221-228,234-236,241-245]


NodeSet=gpu_nodes Nodes=sciml190[2-3],sciml210[1-3],sciml230[1-2],sciml240[1-2]

#
# Partitions
#

PartitionName=production  \
  Nodes=production_nodes \
  Default=YES \
  Priority=10 \
  MaxTime=4-00:00:00 \
  DefaultTime=24:00:00 \
  State=UP \
  PreemptMode=OFF \
  DefMemPerCPU=512

PartitionName=jupyter \
Nodes=jupyter_only_nodes,jupyter_shared_nodes,gpu_nodes \
  DefMemPerCpu=1000 \
  Default=NO \
  Priority=60 \
  MaxTime=24:00:00 \
  DefaultTime=12:00:00 \
  State=UP \
  qos=jupyter

# Note QOS to impose limits.
PartitionName=ifarm \
Nodes=production_nodes \
  DefMemPerCpu=1000 \
  Default=NO \
  Priority=60 \
  MaxTime=24:00:00 DefaultTime=4:00:00 \
  State=UP \
  qos=ifarm

PartitionName=priority \
  Nodes=production_nodes \
  Default=NO \
  Priority=50 \
  MaxTime=24:00:00 \
  DefaultTime=4:00:00 \
  State=UP \
  PreemptMode=OFF \
  DefMemPerCPU=512 \
  qos=priority

PartitionName=theory \
  Nodes=theory_shared_nodes \
  Default=NO \
  Priority=10 \
  MaxTime=4-00:00:00 \
  DefaultTime=24:00:00 \
  State=UP \
  PreemptMode=OFF

PartitionName=scavenger \
  Nodes=production_nodes \
  Default=NO \
  Priority=1 \
  MaxTime=4-00:00:00 \
  DefaultTime=24:00:00 \
  State=UP \
  DefMemPerCPU=512 \
  PreemptMode=CANCEL \
  qos=scavenger \
  GraceTime=60

PartitionName=gpu \
  Nodes=gpu_nodes \
  Default=NO \
  Priority=10 \
  MaxTime=10-00:00:00 \
  DefaultTime=4:00:00 \
  State=UP \
  DefMemPerCpu=512

PartitionName=scavenger_gpu \
  Nodes=gpu_nodes \
  Default=NO \
  Priority=1 \
  MaxTime=4-00:00:00 \
  DefaultTime=24:00:00 \
  State=UP \
  DefMemPerCpu=512 \
  PreemptMode=CANCEL \
  qos=scavenger
